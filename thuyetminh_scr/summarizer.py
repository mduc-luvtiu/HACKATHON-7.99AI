from faster_whisper import WhisperModel
import subprocess
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from underthesea import sent_tokenize
import numpy as np


def extract_audio(video_path, audio_path="audio.wav"):
    command = ['ffmpeg', '-y', '-i', video_path, '-vn',
               '-acodec', 'pcm_s16le', '-ar', '16000', audio_path]
    subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    return audio_path


def transcribe_audio(audio_path, model_size='base'):
    model = WhisperModel(
        model_size, device="cuda" if torch.cuda.is_available() else "cpu")
    segments, _ = model.transcribe(audio_path, beam_size=5, language="vi")
    full_text = " ".join([segment.text for segment in segments])
    return full_text

# def summarize_text(text, max_length=130, min_length=30):
#     """T√≥m t·∫Øt n·ªôi dung ti·∫øng Anh b·∫±ng m√¥ h√¨nh BART"""
#     summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
#     summary = summarizer(text, max_length=max_length,
#                          min_length=min_length, do_sample=False)[0]["summary_text"]
#     return summary

def summarize_text(text, max_sentences=5):
    """T√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát b·∫±ng TF-IDF v√† cosine similarity."""
    sentences = sent_tokenize(text)

    if len(sentences) <= max_sentences:
        return text

    # T√≠nh TF-IDF v√† cosine similarity
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(sentences)
    sim_matrix = cosine_similarity(X, X)

    # T√≠nh ƒë·ªô quan tr·ªçng (importance score)
    scores = sim_matrix.sum(axis=1)
    ranked_sentences = [sentences[i]
                        for i in np.argsort(scores)[-max_sentences:]]

    # Gi·ªØ th·ª© t·ª± c√¢u theo b√†i g·ªëc
    ranked_sentences.sort(key=lambda s: sentences.index(s))

    return ' '.join(ranked_sentences)

import google.generativeai as genai

# ƒê·∫∑t API Key
genai.configure(api_key="AIzaSyB2tZf-KsStJvXJtv_1-phjXuBZ1VCxvIM")  # Thay b·∫±ng key th·∫≠t

# Kh·ªüi t·∫°o model
model = genai.GenerativeModel("gemini-2.0-flash")

def gemini_summarize(text):
    prompt = f"T√≥m t·∫Øt ƒëo·∫°n vƒÉn sau b·∫±ng ti·∫øng Vi·ªát ng·∫Øn g·ªçn, r√µ r√†ng:\n\n{text}"
    response = model.generate_content(prompt)
    return response.text

# V√≠ d·ª•
long_text = """Th·∫ø gi·ªõi ƒëang ch·ª©ng ki·∫øn bi·∫øn ƒë·ªïi kh√≠ h·∫≠u v·ªõi t·ªëc ƒë·ªô nhanh ch√≥ng...
               ...C√°c bi·ªán ph√°p kh·∫©n c·∫•p c·∫ßn ƒë∆∞·ª£c th·ª±c thi ƒë·ªÉ h·∫°n ch·∫ø h·∫≠u qu·∫£ nghi√™m tr·ªçng."""

summary = gemini_summarize(long_text)
print("üìù T√≥m t·∫Øt t·ª´ Gemini:\n", summary)

